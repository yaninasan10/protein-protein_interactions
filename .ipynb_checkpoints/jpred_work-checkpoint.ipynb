{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "database = pd.read_csv('~/database_for_second_struct', nrows=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с загруженной таблицей. Для этого найдем с помощью Jpred API -- A Protein Secondary Structure Prediction Server -- вторичную структуру белков из таблицы. Так как сайт не принимает на вход белки, у которых длина последовательности аминокислот превышает 800, то почистим таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database['Check_A'] = [(len(item) < 800) for item in database['SEQUENCE_A']]\n",
    "database['Check_B'] = [(len(item) < 800) for item in database['SEQUENCE_B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_a = [database['SEQUENCE_A'][i] for i in range(0, 3000)]\n",
    "dict_b = [database['SEQUENCE_A'][i] for i in range(0, 3000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import jpredapi\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью этой функции отправляем данные на сайт и через какое-то время скачиваем файл с готовой вторичной структурой белка. Иногда последовательности аминокислот могут обрабатываться очень долго и врея ожидания будет превышено. В таком случае приходилось вручную останавливать процесс и продолжать с прерванной итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendReq(begin, end, database, dict_):\n",
    "    all_id = {}\n",
    "\n",
    "    for i in range(begin, end):\n",
    "        if database['Check_A'][i]:\n",
    "            if 'U' not in database['SEQUENCE_A'][i]:\n",
    "                request = jpredapi.submit(mode='single', user_format='raw', seq=dict_[i], silent=True)\n",
    "                id_ = request.headers['Location'].split('?')[1]\n",
    "                all_id[database['UNIPROT_SYMBOL_A'][i]] = id_\n",
    "    jobs_left = len(all_id)\n",
    "    del_items = []\n",
    "    BASE_URL = 'http://www.compbio.dundee.ac.uk/jpred4/results/'\n",
    "    \n",
    "    RESULT_DIR = '/home/yanina/protein-protein_interactions/sec_str_a'\n",
    "\n",
    "    while jobs_left:    \n",
    "        for item in del_items:\n",
    "            all_id.pop(item)\n",
    "        del_items = []\n",
    "        for uni_id, id_ in all_id.items():\n",
    "            status = jpredapi.status(id_, silent=True)\n",
    "            if status.content and ('finished' in status.content.decode()):\n",
    "                url = BASE_URL + id_ + '/' + id_ + '.simple.html' \n",
    "                html_result = urllib.request.urlopen(url).read().decode()\n",
    "                html_result = html_result[html_result.find('<!'):]\n",
    "                soup = BeautifulSoup(html_result, 'html')\n",
    "                if uni_id != 'O00623':\n",
    "                    result = soup.get_text(strip=True).split('\\n')[1]                \n",
    "                        # Путь для сохранения, имя файла - id белка\n",
    "                    with open(os.path.join(RESULT_DIR, uni_id + '.txt'), 'w') as file:\n",
    "                        file.write(result)\n",
    "                        print('Was written: %s' % uni_id)\n",
    "                jobs_left -= 1\n",
    "                del_items.append(uni_id)\n",
    "        sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was written: P27361\n",
      "Was written: Q02535\n",
      "Was written: P41240\n",
      "Was written: Q49AN0\n",
      "Was written: Q5T3J3\n",
      "Was written: P31150\n",
      "Was written: O60260\n",
      "Was written: O75175\n",
      "Was written: P21246\n",
      "Was written: P37840\n",
      "Was written: P01100\n",
      "Was written: P04637\n",
      "Was written: P04150\n",
      "Was written: Q8TAU0\n",
      "Was written: Q9H6S3\n",
      "Was written: Q9H213\n",
      "Was written: P26641\n",
      "Was written: P18847\n",
      "Was written: Q92785\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(0, 3000, 30), position=0, leave=True):\n",
    "    sendReq(i, min(i + 30, 3000), database, dict_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, 3000, 30), position=0, leave=True):\n",
    "    sendReq(i, min(i + 30, 3000), database, dict_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
